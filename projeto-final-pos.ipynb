{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Market Basket - Rule and Data Mining</h1>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "APRESENTAÇÃO:\n",
    "\n",
    "Nosso projeto vai analisar a base de dados das cestas de produtos compradas em uma empresa e apresentar, com base em seus padrões e regras, buscar oportunidades sugerindo técnicas e soluções para melhor desempenho da empresa. Futuramente, podemos focar neste nicho de mercado e oferecer este produto para outros varejistas no Brasl e talvez até no mundo todo.\n",
    "\n",
    "Iniciamos com uma entrevista inicial com a empresa TAL, ONDE ... Entender a \"dor\" do cliente. E se tem DB. (Planejamento de tempo - resolver essa parte até 24 de abril de 2022),\n",
    "\n",
    "Além disso, o grupo pesquisou na internet projetos e sites que oferecem soluções semelhantes (projetos de melhor uso de dados de cesta de compras, sistemas de recomendação e clusterização, criação de perfis de consumidor etc. - critérios e categorias de segmentação etc.)\n",
    "\n",
    "A busca no Google Scholar por artigos científicos relacionados a \"Market Basket\" e \"data mining\" para iniciar o trabalho com fundamentação científica resultou em 146 mil artigos: https://scholar.google.com.br/scholar?hl=pt-BR&as_sdt=0%2C5&q=Market+Basket+Data+Mining&btnG=\n",
    "\n",
    "Iniciamos o projeto analisando o \"Association Rule Mining\" ( https://courses.cs.duke.edu/compsci516/spring16/Papers/AssociationRuleMining.pdf ), que apresenta a técnica de mineração de regras de associação, que busca por padrões frequentes em grandes conjuntos de dados. Para isso, são utilizados os conceitos de regras de associação, confiança e suporte, além de serem apresentados os algoritmos Apriori e FP-Growth utilizados na mineração de regras.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RESUMO DO ARTIGO:\n",
    "\n",
    "Um dos desafios na mineração de regras de associação é o problema da escalabilidade, que ocorre quando o tamanho dos conjuntos de dados aumenta, aumentando significativamente o tempo de execução dos algoritmos. Outro problema é a presença de outliers nos dados, que pode afetar a qualidade das regras encontradas.\n",
    "\n",
    "Para lidar com esses problemas, o artigo propõe o uso de medidas como o suporte e a confiança na mineração de regras de associação. O suporte é uma medida de frequência que indica a proporção de transações em que um conjunto de itens aparece juntos. Já a confiança é uma medida que indica a probabilidade de que um item B apareça em uma transação que contém o item A.\n",
    "\n",
    "As fórmulas para o cálculo do suporte e confiança são as seguintes:\n",
    "\n",
    "\n",
    "Suporte (Support):\n",
    "\n",
    "S(A → B) = (N(A ∪ B)) / N\n",
    "onde N é o número total de transações, A e B são conjuntos de itens e N(A ∪ B) é o número de transações que contêm tanto A quanto B.\n",
    "\n",
    "\n",
    "Confiança (Confidence):\n",
    "\n",
    "C(A → B) = (N(A ∪ B)) / N(A)\n",
    "onde N(A) é o número de transações que contêm A.\n",
    "\n",
    "\n",
    "O suporte e a confiança são importantes na mineração de regras de associação, pois permitem avaliar a relevância de uma regra. Uma regra com alto suporte e confiança indica que é um padrão frequente nos dados e tem uma alta probabilidade de ser verdadeiro. Por outro lado, uma regra com baixo suporte e confiança pode ser irrelevante ou pouco confiável.\n",
    "\n",
    "O algoritmo Apriori é utilizado para lidar com a escalabilidade dos dados, utilizando um método de geração de candidatos para construir uma estrutura de dados chamada árvore de itens frequentes. O algoritmo percorre a árvore e avalia a frequência de cada item, a fim de gerar as regras de associação com base nos valores de suporte e confiança estabelecidos.\n",
    "\n",
    "Em resumo, o artigo apresenta as técnicas de mineração de regras de associação, os problemas da escalabilidade e presença de outliers nos dados, e a importância do suporte e confiança na avaliação da relevância das regras de associação encontradas, além de apresentar as fórmulas para o cálculo do suporte e confiança e o funcionamento do algoritmo Apriori."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com base no artigo \"Association Rule Mining with Apriori Algorithm: Implementation in Python\", podemos implementar o algoritmo Apriori para mineração de regras de associação em Python. Abaixo está uma implementação básica com a versão atualizada e as bibliotecas necessárias:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# códigos iniciais do projeto em Python - planejamento de data - até 28/04/2023\n",
    "\n",
    "raw_data_file = 'data/raw/olist_order_payments_dataset.csv' # atualizar dados aqui quando tivermos os dados\n",
    "\n",
    "# Instalando bibliotecas necessárias\n",
    "%pip install mlxtend\n",
    "\n",
    "# Importando bibliotecas necessárias\n",
    "import pandas as pd\n",
    "from mlxtend.frequent_patterns import apriori\n",
    "from mlxtend.frequent_patterns import association_rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 15\u001b[0m\n\u001b[0;32m     13\u001b[0m transactions \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame\u001b[39m.\u001b[39mfrom_records(transactions_list) \n\u001b[0;32m     14\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m, \u001b[39mlen\u001b[39m(df)):\n\u001b[1;32m---> 15\u001b[0m     transactions\u001b[39m.\u001b[39;49mpandas\u001b[39m.\u001b[39mconcatend([\u001b[39mstr\u001b[39m(df\u001b[39m.\u001b[39mvalues[i,j]) \u001b[39mfor\u001b[39;00m j \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m, \u001b[39mlen\u001b[39m(df\u001b[39m.\u001b[39mcolumns))])\n\u001b[0;32m     17\u001b[0m \u001b[39m# Obtendo os itens frequentes # com suporte mínimo de 0.2 - add  min_support=0.2, mesmo sem isso tá dando erro\u001b[39;00m\n\u001b[0;32m     18\u001b[0m frequent_itemsets \u001b[39m=\u001b[39m apriori(transactions, use_colnames\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\generic.py:5902\u001b[0m, in \u001b[0;36mNDFrame.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5895\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[0;32m   5896\u001b[0m     name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_internal_names_set\n\u001b[0;32m   5897\u001b[0m     \u001b[39mand\u001b[39;00m name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_metadata\n\u001b[0;32m   5898\u001b[0m     \u001b[39mand\u001b[39;00m name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_accessors\n\u001b[0;32m   5899\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_info_axis\u001b[39m.\u001b[39m_can_hold_identifiers_and_holds_name(name)\n\u001b[0;32m   5900\u001b[0m ):\n\u001b[0;32m   5901\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m[name]\n\u001b[1;32m-> 5902\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mobject\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__getattribute__\u001b[39;49m(\u001b[39mself\u001b[39;49m, name)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'pandas'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "d = {'name': ['Braund', 'Cummings', 'Heikkinen', 'Allen'],\n",
    "     'age': [22,38,26,35],\n",
    "     'fare': [7.25, 71.83, 0 , 8.05], \n",
    "     'survived?': [False, True, True, False]}\n",
    "\n",
    "df = pd.DataFrame(d)\n",
    "\n",
    "# Lendo o conjunto de dados\n",
    "df = pd.read_csv(raw_data_file, header=None) \n",
    "\n",
    "# Convertendo o conjunto de dados em uma matriz de transações\n",
    "transactions_list = []\n",
    "transactions = pd.DataFrame.from_records(transactions_list) \n",
    "for i in range(0, len(df)):\n",
    "    transactions.pandas.concatend([str(df.values[i,j]) for j in range(0, len(df.columns))])\n",
    "\n",
    "# Obtendo os itens frequentes # com suporte mínimo de 0.2 - add  min_support=0.2, mesmo sem isso tá dando erro\n",
    "frequent_itemsets = apriori(transactions, use_colnames=True)\n",
    "\n",
    "# Obtendo as regras de associação com confiança mínima de 0.7\n",
    "rules = association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=0.7)\n",
    "\n",
    "# Mostrando as regras de associação\n",
    "print(rules)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d143691b3b796dfa840125b678cbcfa24de4daa9df447a44f4f360662660234b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
